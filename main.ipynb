{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "PATH = \"./dataset/\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(PATH, \"train_set.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PATH, \"test_set.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...</td>\n",
       "      <td>0.631486</td>\n",
       "      <td>0.535060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>O[C@@H](CNC1CC1)CN1CCc2sccc2C1</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>1.116781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>N#CCCNC(=O)[C@@]1(O)CCSC1</td>\n",
       "      <td>1.463943</td>\n",
       "      <td>0.964848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.338862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                             SMILES   Reorg_g  \\\n",
       "0  train_0  CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...  0.631486   \n",
       "1  train_1                     O[C@@H](CNC1CC1)CN1CCc2sccc2C1  0.825901   \n",
       "2  train_2                          N#CCCNC(=O)[C@@]1(O)CCSC1  1.463943   \n",
       "3  train_3        COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1  0.166669   \n",
       "4  train_4          N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N  0.313820   \n",
       "\n",
       "   Reorg_ex  \n",
       "0  0.535060  \n",
       "1  1.116781  \n",
       "2  0.964848  \n",
       "3  0.161458  \n",
       "4  0.338862  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ngrams :  6289\n"
     ]
    }
   ],
   "source": [
    "def char_grams(text : str, n : int = 3, jump_size : int = 2):\n",
    "    return [text[i:i+n] for i in range(0, len(text) - n + 1, jump_size)]\n",
    "\n",
    "train_df['3_gram'] = train_df['SMILES'].apply(lambda x : char_grams(x, 3, 2))\n",
    "test_df['3_gram'] = test_df['SMILES'].apply(lambda x : char_grams(x, 3, 2))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df_train, df_test = train_test_split(train_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "x_train, y_train = df_train['SMILES'], df_train[['Reorg_g','Reorg_ex']]\n",
    "x_test, y_test = df_test['SMILES'], df_test[['Reorg_g','Reorg_ex']]\n",
    "\n",
    "vector = CountVectorizer(analyzer='char_wb', ngram_range=(4,4))\n",
    "vector.fit(x_train)\n",
    "\n",
    "x_train_cv = vector.transform(x_train)\n",
    "x_test_cv = vector.transform(x_test)\n",
    "x_sub_cv = vector.transform(test_df)\n",
    "\n",
    "print(\"number of ngrams : \", len(vector.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.111\n",
      "test loss : 0.299\n"
     ]
    }
   ],
   "source": [
    "# RandomForest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "kwargs = {\n",
    "    'n_estimators' : 128,\n",
    "    'n_jobs' : 16,\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(**kwargs)\n",
    "model.fit(x_train_cv, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train_cv)\n",
    "y_test_pred = model.predict(x_test_cv)\n",
    "\n",
    "train_loss = mean_squared_error(y_train, y_train_pred, squared = False)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "print(\"train loss : {:.3f}\".format(train_loss))\n",
    "print(\"test loss : {:.3f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BoW features and training\n",
    "from src.utils import extract_alphabet_dict\n",
    "\n",
    "total_smiles = pd.concat([train_df[['SMILES','index']] , test_df[['SMILES', 'index']]], axis = 0).reset_index(drop = True)\n",
    "char2idx,idx2char = extract_alphabet_dict(total_smiles)\n",
    "\n",
    "alphabet = list(char2idx.keys())\n",
    "\n",
    "train_alphabet_dict = {}\n",
    "test_alphabet_dict = {}\n",
    "\n",
    "n = 4\n",
    "\n",
    "for a in alphabet:\n",
    "    for b in alphabet:\n",
    "        for c in alphabet:\n",
    "            for d in alphabet:\n",
    "                for e in alphabet:\n",
    "                    train_alphabet_dict[f'{a}{b}{c}{d}{e}'] = []\n",
    "                    test_alphabet_dict[f'{a}{b}{c}{d}{e}'] = []\n",
    "\n",
    "for idx, seq in enumerate(train_df['SMILES']):\n",
    "    for i in range(n, len(seq)):\n",
    "        pattern = seq[i-n:i+1]\n",
    "        train_alphabet_dict[pattern].append(idx)\n",
    "\n",
    "for idx, seq in enumerate(test_df['SMILES']):\n",
    "    for i in range(n, len(seq)):\n",
    "        pattern = seq[i-n:i+1]\n",
    "        test_alphabet_dict[pattern].append(idx)\n",
    "\n",
    "train_np_dict = {}\n",
    "test_np_dict = {}\n",
    "\n",
    "key_columns = sorted(train_alphabet_dict, key = lambda x : len(train_alphabet_dict[x]), reverse = True)[:1024]\n",
    "\n",
    "for key in key_columns:\n",
    "    train_df[key] = 0\n",
    "    test_df[key] = 0\n",
    "    train_np_dict[key] = np.zeros(len(train_df))\n",
    "    test_np_dict[key] = np.zeros(len(test_df))\n",
    "\n",
    "for pattern in key_columns:\n",
    "    for idx in train_alphabet_dict[pattern]:\n",
    "        train_np_dict[pattern][idx] += 1\n",
    "    \n",
    "    for idx in test_alphabet_dict[pattern]:\n",
    "        test_np_dict[pattern][idx] += 1\n",
    "    \n",
    "for pattern in key_columns:\n",
    "    train_df[pattern] = train_np_dict[pattern]\n",
    "    test_df[pattern] = test_np_dict[pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import get_mol_properties\n",
    "\n",
    "train_df = get_mol_properties(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cols :  ['MolMR', 'NHOHCount', 'NOCount', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumValenceElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings', 'NumAromaticHeterocycles', 'NumAromaticCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticCarbocycles', 'RingCount', 'FractionCSP3', 'TPSA', 'LabuteASA']\n",
      "y_cols :  ['Reorg_g', 'Reorg_ex']\n"
     ]
    }
   ],
   "source": [
    "x_cols = train_df.columns.drop(['Reorg_g','Reorg_ex','index','3_gram','SMILES']).to_list()\n",
    "y_cols = ['Reorg_g','Reorg_ex']\n",
    "\n",
    "print(\"x_cols : \", x_cols)\n",
    "print(\"y_cols : \", y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.112\n",
      "test loss : 0.294\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(train_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "x_train, y_train = df_train[x_cols], df_train[y_cols]\n",
    "x_test, y_test = df_test[x_cols], df_test[y_cols]\n",
    "\n",
    "kwargs = {\n",
    "    'n_estimators' : 128,\n",
    "    'n_jobs' : 16,\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(**kwargs)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_loss = mean_squared_error(y_train, y_train_pred, squared = False)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "print(\"train loss : {:.3f}\".format(train_loss))\n",
    "print(\"test loss : {:.3f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.139\n",
      "test loss : 0.299\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "kwargs = {\n",
    "    'n_estimators' : 1024,\n",
    "}\n",
    "\n",
    "model = MultiOutputRegressor(LGBMRegressor(**kwargs), n_jobs = 16)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_loss = mean_squared_error(y_train, y_train_pred, squared = False)\n",
    "test_loss = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "print(\"train loss : {:.3f}\".format(train_loss))\n",
    "print(\"test loss : {:.3f}\".format(test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('research-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7bc8097f24747f72629445db54bed151603a8d63744e142002cb75630cca553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
